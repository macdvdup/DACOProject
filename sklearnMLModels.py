# -*- coding: utf-8 -*-
"""Copy of CÃ³pia de Daco_dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tPwiJi5KEvfWkgooLqRDTpG1KwLfOODt

# Manuel Fortunato - DACO PROJECT - CNN vs ML algorthims
"""
import numpy as np
import torch

from BaseDataset import BaseDataset
import os

import matplotlib.pyplot as plt
from sklearn.naive_bayes import MultinomialNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeRegressor
from sklearn import svm
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay



'''
FOR GOOGLE COLLAB
from google.colab import drive 
drive.mount('/gdrive')'''

device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"Using {device} device")

path = os.getcwd() 

trainData= BaseDataset("new_TrainIn3.csv","new_TrainOut3.csv",path)
X_train = trainData.X.to_numpy()
y_train_5d = trainData.y.to_numpy()  # shape (400,5)
y_train_1d = np.argmax(trainData.y.to_numpy(),1) # shape (400, )
print(y_train_1d.shape)

valData = BaseDataset("EvalIn3.csv","EvalOut3.csv",path)
X_val = valData.X.to_numpy()
y_val_onehot = valData.y.to_numpy()
y_val = np.argmax(y_val_onehot,1)
print(y_val.shape)

testData= BaseDataset('TestIn3.csv','TestOut3.csv',path)
X_test = testData.X.to_numpy()
y_test_5d = testData.y.to_numpy()
y_test_1d = np.argmax(testData.y.to_numpy(),1)
print(y_test_1d.shape)

output_classes = ('L. Foot', 'L. Hand','R. Foot','R. Hand','Tongue')


"""**(POPULAR) MACHINE LEARNING ALGORITHMS** -  using sklearn library

k-NEIGHBORS
"""

# define model
modelKNeigh = KNeighborsClassifier(n_neighbors=20)

# fit model
modelKNeigh.fit(X_train, y_train_1d)

# Test it
yhatmodelKNeigh = modelKNeigh.predict(X_test)

accmodelKNeigh = np.mean(yhatmodelKNeigh == y_test_1d)

print(accmodelKNeigh)

# determine the confusion matrix 
confMatrix = confusion_matrix(y_test_1d, yhatmodelKNeigh, normalize = None)
display = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = output_classes)
display= display.plot(cmap=plt.cm.Blues, xticks_rotation=0)
plt.title('Confusion Matrix - KNeighborsClassifier')


"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression

# define model
modelLogReg= LogisticRegression()

# fit model
modelLogReg.fit(X_train, y_train_1d)

# Test it
yhatLogReg = modelLogReg.predict(X_test)

accLogReg = np.mean(yhatLogReg == y_test_1d)

print(accLogReg)

# determine the confusion matrix
confMatrix = confusion_matrix(y_test_1d, yhatLogReg, normalize = None)
display = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = output_classes)
display= display.plot(cmap=plt.cm.Blues, xticks_rotation=0)
plt.title('Confusion Matrix - LogisticRegression')

"""Naive Bayes (Multinomial)"""

# Transform negative inputs to normalized (between 0 and 1)
def normalize(data):
    data_min = np.min(data)
    data_max = np.max(data)
    return (data - data_min) / (data_max - data_min)

modelMultNB = MultinomialNB()

# normalize array to values between [0 1]
normalized_X_train = normalize(X_train)
normalized_X_test = normalize(X_test)

# fit model
modelMultNB.fit(normalized_X_train, y_train_1d)

# Test it
yhatMultNB = modelMultNB.predict(normalized_X_test)

accMultNB = np.mean(yhatMultNB == y_test_1d)

print(accMultNB)

# determine the confusion matrix
confMatrix = confusion_matrix(y_test_1d, yhatMultNB, normalize = None)
display = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = output_classes)
display= display.plot(cmap=plt.cm.Blues, xticks_rotation=0)
plt.title('Confusion Matrix - MultinomialNB')

"""Decision Tree"""

# define model
modelDecTree = DecisionTreeRegressor()

# fit model
modelDecTree.fit(X_train, y_train_1d)

# Test it
yhatDecTree = modelDecTree.predict(X_test)

accDecTree = np.mean(yhatDecTree == y_test_1d)

print(accDecTree)

# determine the confusion matrix
confMatrix = confusion_matrix(y_test_1d, yhatDecTree, normalize = None)
display = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = output_classes)
display= display.plot(cmap=plt.cm.Blues, xticks_rotation=0)
plt.title('Confusion Matrix - DecisionTreeRegressor')


"""Support Vector Machine"""
# define model
modelSVM = svm.SVC(kernel='linear', C=1)

# fit model
modelSVM.fit(X_train, y_train_1d)

# Test it
yhatSVM = modelSVM.predict(X_test)

accSVM = np.mean(yhatSVM == y_test_1d)
print(yhatSVM)

print(accSVM)

# determine the confusion matrix
confMatrix = confusion_matrix(y_test_1d, yhatSVM, normalize = None)
display = ConfusionMatrixDisplay(confusion_matrix = confMatrix, display_labels = output_classes)
display= display.plot(cmap=plt.cm.Blues, xticks_rotation=0)
plt.title('Confusion Matrix - svm')
